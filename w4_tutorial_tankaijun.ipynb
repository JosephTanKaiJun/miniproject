{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd03716d-2d71-4f23-a8c7-b748afeccb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# Python 3.8 is required\n",
    "assert sys.version_info >= (3, 8)\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from utils import display_images\n",
    "from utils import display_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure that optimization is enabled\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "    \n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab859f-2a60-42d6-8573-7288f834a733",
   "metadata": {},
   "source": [
    "## Weekly activity\n",
    "1. Create a **random noise color and grayscale** image. You can set your own width and height, but keep the total number of pixels of both images identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d8d9a26-9ce2-4d1d-9154-a63d3e2f898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel of random noise color image: (200, 200, 3)\n",
      "Pixel of grayscale image: (200, 200)\n"
     ]
    }
   ],
   "source": [
    "h = 200\n",
    "w = 200\n",
    "\n",
    "#random_noise_color image\n",
    "ran_img = np.random.randint(0, 256, (h, w, 3), dtype=np.uint8)\n",
    "\n",
    "#grayscale image\n",
    "gray_img = np.random.randint(0, 256, (h, w), dtype=np.uint8)\n",
    "\n",
    "display_images([ran_img,gray_img],('random noise color image','grayscale image'))\n",
    "\n",
    "print(f\"Pixel of random noise color image: {np.shape(ran_img)}\")\n",
    "print(f\"Pixel of grayscale image: {np.shape(gray_img)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ab3c1-6f02-4433-9f5e-459524fce871",
   "metadata": {},
   "source": [
    "2. Convert the code chunk found under section <a href=\"#Section1\">Divide an image into smaller patches using cropping</a> into a function with the following signature:\n",
    "```python\n",
    "crop_grid(img, num_horizontal_grid, num_vertical_grid, line_color)\n",
    " # img is the source image\n",
    " # num_horizontal_grid and num_vertical_grid are the number of patches along x and y axes.\n",
    " # line_color is the color of the grid line.\n",
    " # The output of the function should be image with grids\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdadc1d7-7f46-45c5-a07d-2bd9ff38bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_grid(img, num_horizontal_grid, num_vertical_grid, line_color):\n",
    "    \n",
    "    ori_img = cv.imread(img)\n",
    "    copy_img = ori_img.copy()\n",
    "    height, width = ori_img.shape[:2]\n",
    "\n",
    "    M, N = int(height / num_vertical_grid), int(width / num_horizontal_grid)\n",
    "\n",
    "    for y in range(0, height, M):\n",
    "        for x in range(0, width, N):\n",
    "            x1 = x + N\n",
    "            y1 = y + M\n",
    "\n",
    "            if x1 >= width and y1 >= height:\n",
    "                x1 = width\n",
    "                y1 = height\n",
    "                cv.rectangle(copy_img, (x, y), (x1, y1), line_color, 1)\n",
    "\n",
    "            elif x1 >= width:\n",
    "                x1 = width - 1\n",
    "                cv.rectangle(copy_img, (x, y), (x1, y1), line_color, 1)\n",
    "\n",
    "            elif y1 >= height:\n",
    "                y1 = height - 1\n",
    "                cv.rectangle(copy_img, (x, y), (x1, y1), line_color, 1)\n",
    "\n",
    "            else:\n",
    "                cv.rectangle(copy_img, (x, y), (x1, y1), line_color, 1)\n",
    "\n",
    "    return copy_img\n",
    "\n",
    "img_crop = crop_grid(\"images/meal.jpg\", 3, 3, (255, 255, 255))\n",
    "display_image('cropped image', img_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a86dd-9774-489d-a671-b0240690f200",
   "metadata": {},
   "source": [
    "3. How would you *change the brightness* of a **color image**? Suggest **two ways** to perform the image processing operations. Implement your methods by providing the example codes. You are free to choose any image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "612a9880-7c92-4b4e-8a46-7612ea624b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first way:convert to hsv color space\n",
    "def colorHSV(img, value):\n",
    "    img_ab = cv.imread(img)\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    img_hsv = cv.cvtColor(img_ab, cv.COLOR_BGR2HSV)\n",
    "    h, s, v = cv.split(img_hsv)\n",
    "\n",
    "    # Adjusting value channel\n",
    "    v_new = cv.add(v, value)\n",
    "    v_new = np.uint8(v_new)\n",
    "    # Merge\n",
    "    transform = cv.merge((h, s, v_new))\n",
    "    return cv.cvtColor(transform, cv.COLOR_HSV2BGR)\n",
    "\n",
    "from utils import display_images\n",
    "v = 50\n",
    "img = cv.imread(\"images/lena.jfif\")\n",
    "img_modified_hsv = colorHSV('images/lena.jfif', v)\n",
    "display_images([img, img_modified_hsv],('original', f\"value={v}\"))\n",
    "\n",
    "#second way: adjust L channel\n",
    "def colorLAB(img, lab):\n",
    "    img_ab = cv.imread(img)\n",
    "    img_lab = cv.cvtColor(img_ab, cv.COLOR_BGR2LAB)\n",
    "    l, a, b = cv.split(img_lab)\n",
    "\n",
    "    l_new = cv.add(l, lab)\n",
    "    l_new = np.uint8(l_new)\n",
    "    transform = cv.merge((l_new, a, b))\n",
    "    return cv.cvtColor(transform, cv.COLOR_LAB2BGR)\n",
    "\n",
    "l = 50\n",
    "img = cv.imread(\"images/lena.jfif\")\n",
    "img_modified_lab = colorLAB('images/lena.jfif', l)\n",
    "display_images([img, img_modified_lab], ('lab', f\"L value={l}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761bfc7-74b2-4360-abd3-8630f053b8d1",
   "metadata": {},
   "source": [
    "4. Provide at least one common use case(s) for the following color spaces:\n",
    "    - RGB\n",
    "    - HSV\n",
    "    - CIELAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201a974-f5c3-4310-a83f-72f231e3f6e5",
   "metadata": {},
   "source": [
    "RGB     = Displaying images on screens (monitors, TVs, smartphones)\n",
    "\n",
    "HSV     = Color-based image segmentation and detection\n",
    "\n",
    "CIELAB  = Color correction and image editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe67fc7-9dee-40a4-aa1d-b641971443ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
